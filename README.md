Project Description

This project tackles online toxicity detection using the Jigsaw Toxic Comment Classification dataset (1.8M+ comments). It classifies harmful content—including insults, threats, and hate speech—in real time. The system integrates ML models (Naive Bayes, RNNs, BERT) into a scalable pipeline, enabling safe and respectful online interactions.

Features

Real-time text classification with sub-second inference latency

Multi-class toxicity detection: mild/severe toxicity, obscenity, threats, insults, identity hate

Confidence scoring & evaluation metrics (Precision, Recall, F1, AUC-ROC)

High scalability: handles 10K+ daily analyses, 95% uptime, and concurrent users

Deployable comment moderation system (Java/Python)

The qualitative results are available in the project report pdf.

Technologies Used

Languages: Python, C++, Java

ML Frameworks: TensorFlow, Keras, HuggingFace Transformers, Scikit-learn

Data: Jigsaw Toxic Comment Classification Dataset (1.8M+ comments)

Deployment: Java/Python APIs, scalable backend with real-time inference
