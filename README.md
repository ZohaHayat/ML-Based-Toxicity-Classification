# Improving Online Safety Through ML-Based Toxicity Classification

## Project Description  
This project tackles online toxicity detection using the Jigsaw Toxic Comment Classification dataset (1.8M+ comments).  
It classifies harmful content, including insults, threats, and hate speech‚Äîin real time using ML models (Naive Bayes, RNNs, BERT).  
The system is deployed as a scalable moderation pipeline with sub-second inference latency and 95% uptime.  

## Features  
- ‚ö° Real-time text classification with sub-second latency  
- üõ° Multi-class toxicity detection: mild/severe toxicity, obscenity, threats, insults, identity hate  
- üìä Confidence scoring & evaluation metrics (Precision, Recall, F1, AUC-ROC)  
- ‚òÅÔ∏è Scalable architecture: 10K+ daily analyses, concurrent users, 95% uptime  
- üîß Deployable moderation system (Java/Python APIs)    

## Technologies Used  
- **Languages**: Python, C++, Java  
- **ML Frameworks**: TensorFlow, Keras, HuggingFace Transformers, Scikit-learn  
- **Data**: Jigsaw Toxic Comment Classification Dataset (1.8M+ comments)  
- **Deployment**: Java/Python APIs, scalable backend with real-time inference  
